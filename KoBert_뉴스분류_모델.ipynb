{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1QHAJ9Zf-99uzvKJD1oa2UQ4QxvfQHJAG","authorship_tag":"ABX9TyM/0hAgTzWJSXDyoc8bYH0C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjeQxRmzVQIp","executionInfo":{"status":"ok","timestamp":1720358458505,"user_tz":-540,"elapsed":33104,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"8b5a051c-bbf8-4744-9bc6-476df46999ed"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-89tuhr7i/kobert-tokenizer_723976c74d3643e2a535de5b867a8aa6\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-89tuhr7i/kobert-tokenizer_723976c74d3643e2a535de5b867a8aa6\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4633 sha256=fd64556dcd399dbea05f2543a864ebfe731ad264213194897579e199f42a1963\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yxo91zce/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6VrpRVX9O4K","executionInfo":{"status":"ok","timestamp":1720359168776,"user_tz":-540,"elapsed":3254,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"30a0e390-9e62-4fcf-f7c0-83f8f7cc8fd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizer_config.json found in the directory.\n","spiece.model found in the directory.\n","special_tokens_map.json found in the directory.\n"]},{"output_type":"execute_result","data":{"text/plain":["KoBERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":8}],"source":["import torch\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","import torch.nn as nn\n","import os\n","\n","# GPU 설정\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 모델 로드 경로 설정\n","MODEL_SAVE_PATH = \"/content/drive/MyDrive/프로젝트/증권 뉴스 분류 및 개체명 인식/kobert_model.pth\"\n","TOKENIZER_SAVE_FOLDER = \"/content/drive/MyDrive/프로젝트/증권 뉴스 분류 및 개체명 인식/kobert_tokenizer\"\n","\n","# 필요한 파일 목록\n","required_files = ['tokenizer_config.json', 'spiece.model', 'special_tokens_map.json']\n","\n","# 파일 존재 여부 확인\n","for file_name in required_files:\n","    file_path = os.path.join(TOKENIZER_SAVE_FOLDER, file_name)\n","    if not os.path.exists(file_path):\n","        raise FileNotFoundError(f\"Error: {file_name} not found in the directory.\")\n","    else:\n","        print(f\"{file_name} found in the directory.\")\n","\n","# KoBERTClass 정의\n","class KoBERTClass(nn.Module):\n","    def __init__(self):\n","        super(KoBERTClass, self).__init__()\n","        self.l1 = BertModel.from_pretrained('skt/kobert-base-v1')\n","        self.pre_classifier = nn.Linear(768, 768)\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(768, 6) # 라벨 수에 맞게 조정\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output\n","\n","# 모델과 토크나이저 로드\n","model = KoBERTClass()\n","model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n","tokenizer = KoBERTTokenizer.from_pretrained(TOKENIZER_SAVE_FOLDER)\n","\n","# GPU로 모델 이동\n","model.to(device)"]},{"cell_type":"code","source":["# 예제 문장 분류\n","example_sentence = [\n","    \"애플이 스타업을 인수하려고 합니다\",\n","\n","]\n","\n","# 문장을 토크나이저로 전처리\n","inputs = tokenizer.encode_plus(\n","    example_sentence,\n","    None,\n","    add_special_tokens=True,\n","    max_length=128,\n","    pad_to_max_length=True,\n","    return_token_type_ids=True,\n","    return_attention_mask=True,\n","    return_tensors='pt'\n",")\n","\n","ids = inputs['input_ids'].to(device, dtype=torch.long)\n","mask = inputs['attention_mask'].to(device, dtype=torch.long)\n","token_type_ids = inputs['token_type_ids'].to(device, dtype=torch.long)\n","\n","# 모델을 평가 모드로 전환\n","model.eval()\n","\n","# 모델에 입력하여 결과 도출\n","with torch.no_grad():\n","    outputs = model(ids, mask, token_type_ids)\n","    prediction = torch.argmax(outputs, dim=1).item()\n","\n","# 라벨별 이름을 설정 (필요시 수정)\n","label_names = [\"시황/전망\", \"기업/종목분석\", \"해외증시\", \"채권/선물\", \"공시/메모\", \"환율\"]\n","\n","# 결과 출력\n","print(f\"문장: '{example_sentence}'\")\n","print(f\"분류 결과: {label_names[prediction]} (라벨: {prediction})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsAv1BrpZaTI","executionInfo":{"status":"ok","timestamp":1720359242258,"user_tz":-540,"elapsed":569,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"71dcff4f-3fbd-47df-e193-00628a694925"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["문장: '애플이 스타업을 인수하려고 합니다'\n","분류 결과: 해외증시 (라벨: 2)\n"]}]}]}